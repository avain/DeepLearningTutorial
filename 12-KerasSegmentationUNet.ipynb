{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 本筆記的目的：了解如何以UNet來分割影像。\n",
    "\n",
    "此範例使用[Carvana Image Masking Challenge](https://www.kaggle.com/c/carvana-image-masking-challenge)所提供的資料集。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 索引\n",
    "\n",
    "1. [準備資料](#1.-準備資料)\n",
    "2. [檢視資料集](#2.-檢視資料集)\n",
    "3. [訓練模型](#3.-訓練模型)\n",
    "4. [拿訓練好的模型做預測](#4.-拿訓練好的模型做預測)\n",
    "5. [後記](#5.-後記)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "\n",
    "from unet import get_unet, UNet_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 準備資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 給予路徑資訊\n",
    "data_dir = \"../datasets/kaggle-car-segmentation/train/\"        # 圖路徑\n",
    "mask_dir = \"../datasets/kaggle-car-segmentation/train_masks/\"  # 遮罩路徑\n",
    "\n",
    "all_images = os.listdir(data_dir)\n",
    "print(\"number of images =\", len(all_images) )                  # 印出圖片數\n",
    "\n",
    "# 將資料切分為 訓練資料(用於訓練模型) & 驗證資料(用於驗證模型)\n",
    "train_images, validation_images = train_test_split(all_images, train_size=0.8, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[返回索引]](#索引)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 檢視資料集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 得到一個generator，每次可得出8筆資料。\n",
    "batch_size = 8\n",
    "train_gen = UNet_utils.data_gen_small(data_dir, mask_dir, train_images, batch_size, (128, 128) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, masks = next(train_gen)                 # 從generator撈出8筆資料。\n",
    "                                                # 資料分別是圖，以及其相對應的遮罩。\n",
    "assert len(images) == len(masks) == batch_size  # 確定撈出來的資料真的是有8筆。\n",
    "\n",
    "# 檢視資料：從撈出來的資料中，畫出五張圖與其相應遮罩。\n",
    "fig,axes = plt.subplots(5,2,figsize=(10,20))\n",
    "\n",
    "for idx,(image,mask) in enumerate( zip(images,masks) ):\n",
    "    axes[idx,0].imshow(image)\n",
    "    axes[idx,1].imshow( UNet_utils.grey2rgb(mask), alpha=0.5 )\n",
    "    \n",
    "    axes[idx,0].axis('off')\n",
    "    axes[idx,1].axis('off')\n",
    "    \n",
    "    if idx ==4:\n",
    "        break\n",
    "\n",
    "# plt.imshow(img[0])\n",
    "# plt.imshow(grey2rgb(msk[0]), alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[返回索引]](#索引)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 訓練模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取得UNet模型\n",
    "model = get_unet()\n",
    "# 看一下模型摘要\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_metric(y_true, y_pred, smooth = 1.E-6):\n",
    "    '''定義Dice metric。'''\n",
    "    \n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    \n",
    "    return 2.*intersection  / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    '''定義Dice loss。\n",
    "       註：Dice metric越高，代表mask學的越好。因此，我們的目標是讓機器去嘗試最大化Dice metric。\n",
    "    '''\n",
    "    return -dice_metric(y_true, y_pred)\n",
    "\n",
    "# 訓練模型\n",
    "model.compile(optimizer=Adam(1e-4), loss=dice_loss, metrics=[dice_metric])\n",
    "train_record = model.fit_generator(train_gen, steps_per_epoch=100, epochs=5)\n",
    "\n",
    "# 檢視模型訓練情形\n",
    "plt.plot(train_record.history['dice_metric'],ms=5,marker='o',label='dice metric')\n",
    "plt.plot(train_record.history['loss'],ms=5,marker='o',label='loss')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[返回索引]](#索引)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 拿訓練好的模型做預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 得到可以產生驗證資料的generator。\n",
    "batch_size = 8\n",
    "val_gen = UNet_utils.data_gen_small(data_dir, mask_dir, train_images, batch_size, (128, 128) )\n",
    "\n",
    "images, masks = next(val_gen)                   # 從generator撈出8筆資料來看一下。\n",
    "                                                # 資料分別是圖，以及其相對應的遮罩。\n",
    "assert len(images) == len(masks) == batch_size  # 確定撈出來的資料真的是有8筆。\n",
    "\n",
    "mask_preds = model.predict(images)              # 拿剛建好的模型去預測圖片所對應的遮罩樣貌。\n",
    "\n",
    "# 檢視資料：畫出五張圖，相應遮罩(真實)，相應遮罩(預測)。\n",
    "fig,axes = plt.subplots(5,3,figsize=(15,20))\n",
    "fig.suptitle(\"Left to Right: image, mask (ground truth), mask (prediction)\",fontsize=\"30\",y=1.02)\n",
    "\n",
    "for idx,(image,mask,mask_pred) in enumerate( zip(images,masks, mask_preds) ):\n",
    "\n",
    "    axes[idx,0].imshow(image)\n",
    "    axes[idx,1].imshow( UNet_utils.grey2rgb(mask), alpha=0.5 )\n",
    "    axes[idx,2].imshow( UNet_utils.grey2rgb(mask_pred), alpha=0.5 )\n",
    "    \n",
    "    axes[idx,0].axis('off')\n",
    "    axes[idx,1].axis('off')\n",
    "    axes[idx,2].axis('off')\n",
    "    \n",
    "    if idx ==4:\n",
    "        break\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[返回索引]](#索引)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. 後記\n",
    "\n",
    "1. 我們於訓練模型的時候，並沒有使用到驗證資料(validation data)來做驗證。請嘗試將驗證資料餵給模型去做驗證。\n",
    "2. 我們的資料相當理想，因為汽車大小都差不多。然而，實際在路上拍攝時，因為鏡頭和汽車的距離不一定，車的大小也會不太一樣。且於白天，黑夜，下雨，下雪，不同的環境下，攝影機拍出來的影像看起來會不一樣。若需要模型比較能夠應付各種不同的情況，我們得需要擁有更豐富的訓練資料，又或者，於建模時，嘗試使用*資料增益* (*data augmentation*)。\n",
    "3. 我們自定義的generator速度太慢了，GPU工作的很沒效率，因為它一直在等generator從硬碟載入資料給它。解決方案：\n",
    "    1. 把所有資料載入至電腦的RAM，然後從RAM去載入資料(會比從硬碟載入還要快很多)至GPU。\n",
    "    2. 做出一個generator。該generator會以*multi-threading*或*multi-processing*的方式，從硬碟將資料載入至RAM。若資料非常大，無法將其全部放置於RAM，那麼，我們會希望把資料放置於一個固定大小的*queue*(於RAM裡面)。這個*queue*必須隨時處於滿載的情況，這樣，GPU需要資料的時候，就可以即時的去那邊提取資料。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[返回索引]](#索引)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
