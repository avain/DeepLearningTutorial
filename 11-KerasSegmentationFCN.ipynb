{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 目標：從空拍圖裡找出鯨魚，將鯨魚和大海分割。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img_whales](https://kaggle2.blob.core.windows.net/competitions/kaggle/4521/media/ChristinKhan_RightWhaleMomCalf_640.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們將建立一個完全不使用Dense層的Fully Convolutional Network (FCN)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "數據來源：\n",
    "\n",
    "https://www.kaggle.com/c/noaa-right-whale-recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 本筆記內容如下\n",
    "\n",
    "* [I. 宣告模型架構及訓練方式](#31)\n",
    "* [II. 訓練模型三步驟：1. 將圖像準備好成為適合訓練的格式 2. 訓練模型 3. 畫出訓練過程](#32)\n",
    "* [III. 檢驗模型好壞](#33)\n",
    "* [IV. 拿訓練好的網路來做預測](#34)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # =====================================================================\n",
    "# # 由於課堂上可能有多人共用同一顆GPU，以下限定使用者只能使用計算卡上面一半的記憶體。\n",
    "# import tensorflow as tf\n",
    "# from keras.backend.tensorflow_backend import set_session\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.5 # 使用一半記憶體\n",
    "# set_session(tf.Session(config=config))\n",
    "# # ====================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os,time,json\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.models import model_from_json\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Conv2D\n",
    "from whales_model import SoftmaxMap, my_ConvNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='31'>I. 宣告模型架構及訓練方式</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立模型\n",
    "input_shape=(227,227,3)\n",
    "model=my_ConvNet(input_shape) # 一個簡易的CNN模型(不含後面的分類器)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 看一下模型摘要\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上，我們透過5個Conv層來做特徵擷取。接著，我們將疊加分類器進入網路，如此才能將擷取到的特徵做分類。\n",
    "\n",
    "一般來說，分類器會是2至3個Dense層組成的，但是，以下我們以兩個Conv層來取代Dense層："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layers = [Conv2D(filters=4096, kernel_size=1,\n",
    "                      strides=1,\n",
    "                      padding='SAME',\n",
    "                      activation='relu'),\n",
    "               Conv2D(filters=4096, kernel_size=1,\n",
    "                      strides=1,\n",
    "                      padding='SAME',\n",
    "                      activation='relu')\n",
    "              ]\n",
    "\n",
    "# 將兩層個用來分類的Conv層添加至模型裡。這兩個Conv層取代了一般Dense層的地位。\n",
    "for layer in conv_layers:\n",
    "    model.add(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接著，我們想要再添加一層Conv layer, 將輸出Tensor的形狀變成 ```(None,1,1,2)```。末端維度長之所以改成2，是因為我們想要預測出有/無鯨魚，這兩種可能性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 練習：試著添加Conv2D, 將輸出Tensor形狀改變成 (#samples,1,1,2) \n",
    "\n",
    "# model.add( Conv2D(...)\n",
    "#          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "於訓練階段，圖的大小我們會固定為227 X 227。於此階段，機器要學習出，什麼樣的圖特徵看起來是有鯨魚，什麼樣的圖特徵看起來是沒鯨魚。\n",
    "\n",
    "之後，於預測階段，我們會丟一張大圖(也許大小是1000 X 2000左右)進來此網路。此網路將能夠預測，此大圖的各局部區域是否存在鯨魚。\n",
    "\n",
    "因此，我們需要讓模型可以接受任何長寬的圖片。為了達到這個目的，我們必須重建模型，告知其輸入圖片的長寬應為任意大小。\n",
    "\n",
    "換句話說，我們得將input_shape更改為```(None,None,3)```，然後重建模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立模型\n",
    "input_shape=(None,None,3)\n",
    "model=my_ConvNet(input_shape)\n",
    "\n",
    "# 添加兩層末端分類器\n",
    "conv_layers = [Conv2D(filters=4096, kernel_size=1,\n",
    "                      strides=1,\n",
    "                      padding='SAME',\n",
    "                      activation='relu'),\n",
    "               Conv2D(filters=4096, kernel_size=1,\n",
    "                      strides=1,\n",
    "                      padding='SAME',\n",
    "                      activation='relu')\n",
    "              ]\n",
    "for layer in conv_layers:\n",
    "    model.add(layer)\n",
    "\n",
    "# 添加一層特製的Conv層，它能夠使得最後的Tensor只能紀錄兩個信號：有或無鯨魚。\n",
    "model.add( Conv2D(2,kernel_size=3))\n",
    "# 添加Softmax函數，輸出有/無鯨魚的機率。\n",
    "model.add( SoftmaxMap() )\n",
    "\n",
    "# 編譯模型，告知模型學習方式\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(lr=0.01,momentum=0.9,nesterov=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='32'> II. 訓練模型三步驟：1. 將圖像準備好成為適合訓練的格式 2. 訓練模型 3. 畫出訓練過程 </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "epochs=3\n",
    "batch_size=128\n",
    "\n",
    "# 將圖像準備好成為適合訓練的格式 \n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    samplewise_center=True,\n",
    "    rescale=1./255,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(\n",
    "        samplewise_center=True,\n",
    "        rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        '../datasets/whale2/data/train',\n",
    "        target_size=(227, 227),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical', \n",
    "        shuffle=True)\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "        '../datasets/whale2/data/val',\n",
    "        target_size=(227, 227),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical', \n",
    "        shuffle=True)\n",
    "\n",
    "def generatorReshapingLabel(generator):\n",
    "    '''以flow_from_directory產生的generator其標籤格式不符合我們所需，故我們需重新整理標籤的格式。'''\n",
    "    num_classes=len(generator.class_indices)\n",
    "    for x, y in generator:\n",
    "        yield (x, y.reshape((-1,1,1,num_classes)) )\n",
    "        \n",
    "train_generator = generatorReshapingLabel(train_generator)\n",
    "val_generator   = generatorReshapingLabel(val_generator)\n",
    "\n",
    "# 訓練模型\n",
    "history=model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=7268 // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=1818// batch_size)\n",
    "\n",
    "# 畫出訓練過程\n",
    "plt.plot(history.history['acc'],ms=5,marker='o',label='accuracy')\n",
    "plt.plot(history.history['val_acc'],ms=5,marker='o',label='val accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 儲存模型架構\n",
    "with open('../checkpoints/first_try_fcn.json', 'w') as jsOut:\n",
    "    json.dump(model.to_json(), jsOut)\n",
    "# 儲存訓練好的模型權重\n",
    "model.save_weights('../checkpoints/first_try_fcn.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='33'> III. 檢驗模型好壞</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testGen = ImageDataGenerator(\n",
    "        samplewise_center=True,\n",
    "        rescale=1./255).flow_from_directory(\n",
    "        '../datasets/whale2/data/val',\n",
    "        target_size=(227, 227),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical', \n",
    "        shuffle=False)\n",
    "\n",
    "print('\\n')\n",
    "print( testGen.class_indices ,'\\n')\n",
    "yTrue=testGen.classes\n",
    "\n",
    "predictions_last_epoch=model.predict_generator(generator=testGen,steps=1818// batch_size +1)\n",
    "yPredicted=predictions_last_epoch.argmax(axis=-1)\n",
    "yPredicted=yPredicted.reshape(yPredicted.shape[0])\n",
    "print(classification_report(yTrue , yPredicted, digits = 6))\n",
    "\n",
    "print('accuracy=',np.sum(yTrue==yPredicted)/len(yTrue))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='34'>IV. 拿訓練好的 Fully Convolutional Network 來做預測</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelLoad(modelPath,weightsPath):\n",
    "    '''此方法用來載入已經儲存好的模型和模型所學好的權重。'''\n",
    "\n",
    "    # load the previous stored model\n",
    "    with open(modelPath,'r') as jsIn:\n",
    "        modelJson=json.load(jsIn)\n",
    "\n",
    "    model=model_from_json(modelJson)\n",
    "    model.load_weights(weightsPath)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inferImagePreprocessing(imagePath):\n",
    "    '''此方法將一張輸入的大圖轉變成模型能夠拿來使用的格式。'''\n",
    "    \n",
    "    # load the image and display it\n",
    "    image=load_img(imagePath)\n",
    "    image\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "    # convert it to the numerical array\n",
    "    imageArray=img_to_array(image)\n",
    "    print('shape of the image=',imageArray.shape)\n",
    "\n",
    "    # reshape the image to 4D, as the shape of our input\n",
    "    # should be (#samples, height, width, #channels)\n",
    "    imageArray=imageArray.reshape((-1,*imageArray.shape) )\n",
    "    print('\\nshape of the image=',imageArray.shape)\n",
    "\n",
    "    # rescale the image\n",
    "    imgGen = ImageDataGenerator( samplewise_center=True,\n",
    "                                    rescale=1./255. )\n",
    "    generator = imgGen.flow( imageArray,\n",
    "                             batch_size=1,\n",
    "                             shuffle=False )\n",
    "    # pick the rescaled image up from the generator\n",
    "    for idx,figArray in enumerate(generator):\n",
    "        if idx>0:\n",
    "            break    \n",
    "    return figArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 預處理要預測的圖像\n",
    "figArray=inferImagePreprocessing('../datasets/whale2/data/samples/w_3.jpg')\n",
    "# 載入先前訓練好的模型之權重\n",
    "#model.load_weights('../checkpoints/first_try_fcn.h5')\n",
    "# 用模型來做預測\n",
    "start = time.time()\n",
    "prediction = model.predict(figArray)\n",
    "prediction=prediction[0].argmax(-1)\n",
    "end = time.time()\n",
    "# 畫出預測結果\n",
    "plt.imshow( prediction )\n",
    "plt.show()\n",
    "print ('Inference time = %s ' % str(end-start) + ' seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[回索引](#本筆記內容如下)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 後記\n",
    "我們簡介了何謂FCN，以及如何建立，訓練出一個簡單的FCN模型。若想深入了解，或者是嘗試建立出能夠實際拿來應用的模型，我建議你參考以下幾個教學範例(MXNet Gluon)：\n",
    "* https://gluon-cv.mxnet.io/build/examples_segmentation/demo_fcn.html\n",
    "* https://gluon-cv.mxnet.io/build/examples_segmentation/train_fcn.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
